# scripts/debug_llm.py
"""Script para debug do serviÃ§o LLM."""

import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.infrastructure.external.gemini_service import GeminiLLMService

if __name__ == "__main__":
    """Debug do serviÃ§o LLM."""
    print("ğŸ”§ Debug - ServiÃ§o LLM (Gemini)")
    print("=" * 50)

    try:
        llm = GeminiLLMService()
        print("ğŸ§  Testando geraÃ§Ã£o de embedding...")
        print(
            f"ğŸ“Š DimensÃ£o do embedding: {len(llm.generate_embedding('This is a test'))}"
        )
        print("ğŸ”„ Testando conversÃ£o NL para SQL...")
        print(
            f"ğŸ“ SQL gerado: {
                llm.natural_to_sql(
                    'How many records are there?',
                    {'test_table': 'string', 'count': 'integer'},
                )
            }"
        )
        print("ğŸ“‹ Testando sumarizaÃ§Ã£o...")
        values = [("100",), ("200",), ("300",)]
        print(f"ğŸ“„ Resumo: {llm.summarize_results('Test question', values)[:100]}...")
        print("âœ… Debug do LLM concluÃ­do!")

    except Exception as e:
        print(f"âŒ Erro no debug do LLM: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
